def fetch_image_urls_utilurl,driver_path:
    with webdriver.Chromeexecutable_path=driver_path as wd:
            wd.geturl
        thumbnail_results = wd.find_elements_by_css_selector"img[class ='irc_mi']"
            if img.get_attribute'src' and 'http' in img.get_attribute('src'):
                images.appendimg.get_attribute('src')
def fetch_image_urlsquery:str, max_links_to_fetch:int, wd, sleep_between_interactions:int=1,driver_path= None, target_path = None, search_term = None:
    target_folder = os.path.jointarget_path,'_'.join(search_term.lower().split(' '))
    def scroll_to_endwd:
        wd.execute_script"window.scrollTo(0, document.body.scrollHeight);"
        time.sleepsleep_between_interactions    
    wd.getsearch_url.format(q=query)
    image_urls = set
        scroll_to_endwd
        thumbnail_results = wd.find_elements_by_css_selector"img.Q4LuWd"
        number_results = lenthumbnail_results
        printf"Found: {number_results} search results. Extracting links from {results_start}:{number_results}"
                img.click
                time.sleepsleep_between_interactions
                printe
            links = wd.find_elements_by_css_selector"a[jsname='sTFXNd']"
                if link.get_attribute'href' and 'http' in link.get_attribute('href'):
                    if link.get_attribute'href' not in d:
                        d[link.get_attribute'href'] = True
                        getactualurl = fetch_image_urls_utillink.get_attribute('href'),driver_path
                            image_urls.addimageurl
            image_count2 = lenimage_urls
            printimage_count2
                printf"Found: {len(image_urls)} image links, saving!"
                        persist_imagetarget_folder,elem
                    printe
                image_urls = set
        if lenimage_urls >= max_links_to_fetch:
            printf"Found: {len(image_urls)} image links, done!"
            print"Found:", len(image_urls), "image links, looking for more ..."
            time.sleep30
            load_more_button = wd.find_element_by_css_selector".mye4qd"
                wd.execute_script"document.querySelector('.mye4qd').click();"
    printlen(image_urls)
def persist_imagefolder_path:str,url:str:
        image_content = requests.geturl.content
        printf"ERROR - Could not download {url} - {e}"
        image_file = io.BytesIOimage_content
        image = Image.openimage_file.convert('RGB')
        file_path = os.path.joinfolder_path,hashlib.sha1(image_content).hexdigest()[:10] + '.jpg'
        with openfile_path, 'wb' as f:
            image.savef, "JPEG", quality=85
        printf"SUCCESS - saved {url} - as {file_path}"
        printf"ERROR - Could not save {url} - {e}"
def search_and_downloadsearch_term:str,driver_path:str,target_path='./datasets',number_images=50:
    target_folder = os.path.jointarget_path,'_'.join(search_term.lower().split(' '))
    if not os.path.existstarget_folder:
        os.makedirstarget_folder
    with webdriver.Chromeexecutable_path=driver_path as wd:
        res = fetch_image_urlssearch_term, number_images, wd=wd, sleep_between_interactions=0.5,driver_path= driver_path,target_path= target_path,search_term=search_term
            persist_imagetarget_folder,elem
        printe
    search_and_downloadq,"./chromedriver.exe"