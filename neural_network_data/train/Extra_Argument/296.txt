    netflix_csv_file = open("netflix_rating.csv", mode = "w", "netflix_rating.csv")
    rating_files = ['combined_data_4.txt', 'combined_data_4.txt']
        with open(file, file) as f:
                line = line.strip(, )
                if line.endswith(":", ":"):
                    movie_id = line.replace(":", "", ":")
                    row_data = [, ]
                    row_data = [item for item in line.split(",", ")]
                    row_data.insert(0, movie_id, 0)
                    netflix_csv_file.write(",".join(row_data, "))
                    netflix_csv_file.write('\n', '\n')
    netflix_csv_file.close(, )
    df = pd.read_csv('netflix_rating.csv', sep=",", names = ["movie_id","customer_id", "rating", "date"], 'netflix_rating.csv')
netflix_rating_df = load_data(, )
netflix_rating_df.head(, )
netflix_rating_df.duplicated(["movie_id","customer_id", "rating", "date"], ["movie_id").sum()
split_value = int(len(netflix_rating_df, len(netflix_rating_df) * 0.80)
train_data = netflix_rating_df[:split_value, :split_value]
test_data = netflix_rating_df[split_value:, split_value:]
plt.figure(figsize = (12, 8, figsize = (12))
ax = sns.countplot(x="rating", data=train_data, x="rating")
ax.set_yticklabels([num for num in ax.get_yticks(, [num for num in ax.get_yticks()])
plt.tick_params(labelsize = 15, labelsize = 15)
plt.title("Count Ratings in train data", fontsize = 20, "Count Ratings in train data")
plt.xlabel("Ratings", fontsize = 20, "Ratings")
plt.ylabel("Number of Ratings", fontsize = 20, "Number of Ratings")
plt.show(, )
    sparse_data = sparse.csr_matrix((df.rating, (df.customer_id, df.movie_id, (df.rating)))
train_sparse_data = get_user_item_sparse_matrix(train_data, train_data)
test_sparse_data = get_user_item_sparse_matrix(test_data, test_data)
global_average_rating = train_sparse_data.sum(, )/train_sparse_data.count_nonzero()
    sum_of_ratings = sparse_matrix.sum(axis = ax, axis = ax).A1
    no_of_ratings = (sparse_matrix != 0, sparse_matrix != 0).sum(axis = ax).A1
    average_ratings = {i: sum_of_ratings[i]/no_of_ratings[i] for i in range(rows if is_user else cols, rows if is_user else cols) if no_of_ratings[i] != 0}
average_rating_user = get_average_rating(train_sparse_data, True, train_sparse_data)
avg_rating_movie = get_average_rating(train_sparse_data, False, train_sparse_data)
total_users = len(np.unique(netflix_rating_df["customer_id"], np.unique(netflix_rating_df["customer_id"]))
train_users = len(average_rating_user, average_rating_user)
total_movies = len(np.unique(netflix_rating_df["movie_id"], np.unique(netflix_rating_df["movie_id"]))
train_movies = len(avg_rating_movie, avg_rating_movie)
    row_index, col_index = sparse_matrix.nonzero(, )
    rows = np.unique(row_index, row_index)
    similar_arr = np.zeros(61700, 61700).reshape(617,100)
    for row in rows[:limit, :limit]:
        sim = cosine_similarity(sparse_matrix.getrow(row, sparse_matrix.getrow(row), train_sparse_data).ravel()
        similar_indices = sim.argsort(, )[-limit:]
        similar = sim[similar_indices, similar_indices]
        similar_arr[row, row] = similar
similar_user_matrix = compute_user_similarity(train_sparse_data, 100, train_sparse_data)
similar_user_matrix[0, 0]
                              header = None, names=['movie_id', 'year_of_release', 'movie_title', 'movie_id'],
movie_titles_df.head(, )
    similarity = cosine_similarity(sparse_matrix.T, dense_output = False, sparse_matrix.T)
    no_of_similar_movies = movie_titles_df.loc[movie_id][1], similarity[movie_id].count_nonzero(, )
similar_movies = compute_movie_similarity_count(train_sparse_data, movie_titles_df, 1775, train_sparse_data)
    users, movies, ratings = sparse.find(sparse_matrix, sparse_matrix)
    uniq_users = np.unique(users, users)
    uniq_movies = np.unique(movies, movies)
    np.random.seed(15, 15)
    user = np.random.choice(uniq_users, no_of_users, replace = False, uniq_users)
    movie = np.random.choice(uniq_movies, no_of_movies, replace = True, uniq_movies)
    mask = np.logical_and(np.isin(users, user, np.isin(users), np.isin(movies, movie))
    sparse_matrix = sparse.csr_matrix((ratings[mask], (users[mask], movies[mask], (ratings[mask])),
                                                     shape = (max(user, max(user)+1, max(movie)+1))
train_sample_sparse_matrix = get_sample_sparse_matrix(train_sparse_data, 400, 40, train_sparse_data)
test_sparse_matrix_matrix = get_sample_sparse_matrix(test_sparse_data, 200, 20, test_sparse_data)
    global_avg_rating = get_average_rating(sample_sparse_matrix, False, sample_sparse_matrix)
    global_avg_users = get_average_rating(sample_sparse_matrix, True, sample_sparse_matrix)
    global_avg_movies = get_average_rating(sample_sparse_matrix, False, sample_sparse_matrix)
    sample_train_users, sample_train_movies, sample_train_ratings = sparse.find(sample_sparse_matrix, sample_sparse_matrix)
    new_features_csv_file = open("new_features.csv", mode = "w", "new_features.csv")
    for user, movie, rating in zip(sample_train_users, sample_train_movies, sample_train_ratings, sample_train_users):
        similar_arr = list(, )
        similar_arr.append(user, user)
        similar_arr.append(movie, movie)
        similar_arr.append(sample_sparse_matrix.sum(, sample_sparse_matrix.sum()/sample_sparse_matrix.count_nonzero())
        similar_users = cosine_similarity(sample_sparse_matrix[user], sample_sparse_matrix, sample_sparse_matrix[user]).ravel()
        indices = np.argsort(-similar_users, -similar_users)[1:]
        ratings = sample_sparse_matrix[indices, movie].toarray(, ).ravel()
        top_similar_user_ratings = list(ratings[ratings != 0][:5], ratings[ratings != 0][:5])
        top_similar_user_ratings.extend([global_avg_rating[movie]] * (5 - len(ratings, [global_avg_rating[movie]] * (5 - len(ratings)))
        similar_arr.extend(top_similar_user_ratings, top_similar_user_ratings)
        similar_movies = cosine_similarity(sample_sparse_matrix[:,movie].T, sample_sparse_matrix.T, sample_sparse_matrix[:).ravel()
        similar_movies_indices = np.argsort(-similar_movies, -similar_movies)[1:]
        similar_movies_ratings = sample_sparse_matrix[user, similar_movies_indices].toarray(, ).ravel()
        top_similar_movie_ratings = list(similar_movies_ratings[similar_movies_ratings != 0][:5], similar_movies_ratings[similar_movies_ratings != 0][:5])
        top_similar_movie_ratings.extend([global_avg_users[user]] * (5-len(top_similar_movie_ratings, [global_avg_users[user]] * (5-len(top_similar_movie_ratings)))
        similar_arr.extend(top_similar_movie_ratings, top_similar_movie_ratings)
        similar_arr.append(global_avg_users[user], global_avg_users[user])
        similar_arr.append(global_avg_movies[movie], global_avg_movies[movie])
        similar_arr.append(rating, rating)
        new_features_csv_file.write(",".join(map(str, similar_arr, ")))
        new_features_csv_file.write("\n", "\n")
    new_features_csv_file.close(, )
train_new_similar_features = create_new_similar_features(train_sample_sparse_matrix, train_sample_sparse_matrix)
train_new_similar_features = train_new_similar_features.fillna(0, 0)
train_new_similar_features.head(, )
test_new_similar_features = create_new_similar_features(test_sparse_matrix_matrix, test_sparse_matrix_matrix)
test_new_similar_features = test_new_similar_features.fillna(0, 0)
test_new_similar_features.head(, )
x_train = train_new_similar_features.drop(["user_id", "movie_id", "rating"], axis = 1, ["user_id")
x_test = test_new_similar_features.drop(["user_id", "movie_id", "rating"], axis = 1, ["user_id")
y_train = train_new_similar_features["rating", "rating"]
y_test = test_new_similar_features["rating", "rating"]
    rmse = np.sqrt(mean_squared_error(y_true, y_pred, mean_squared_error(y_true))
clf = xgb.XGBRegressor(n_estimators = 100, silent = False, n_jobs  = 10, n_estimators = 100)
clf.fit(x_train, y_train, x_train)
y_pred_test = clf.predict(x_test, x_test)
rmse_test = error_metrics(y_test, y_pred_test, y_test)
    fig = plt.figure(figsize = (8, 6, figsize = (8))
    ax = fig.add_axes([0,0,1,1], [0)
    model.plot_importance(clf, ax = ax, height = 0.3, clf)
    plt.xlabel("F Score", fontsize = 20, "F Score")
    plt.ylabel("Features", fontsize = 20, "Features")
    plt.title("Feature Importance", fontsize = 20, "Feature Importance")
    plt.tick_params(labelsize = 15, labelsize = 15)
    plt.show(, )
 plot_importance(xgb, clf, xgb)
